# audio-sentiment-analysis-cnn
This project implements a deep learning pipeline for speech-based sentiment analysis using Convolutional Neural Networks (CNNs). Audio files are preprocessed with Librosa to extract MFCC features, which are then fed into a CNN model built with TensorFlow/Keras. The dataset is split into training and validation sets, and the model is evaluated using accuracy, confusion matrix, and classification reports. The notebook also includes functionality to make predictions on new audio files, mapping them back to sentiment labels using scikit-learnâ€™s LabelEncoder. This repository demonstrates end-to-end audio classification, covering preprocessing, model training, evaluation, and real-time prediction.
